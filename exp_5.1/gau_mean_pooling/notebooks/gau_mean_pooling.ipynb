{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8a63c08-dc68-4c34-b4e3-0323f590b9ae",
   "metadata": {},
   "source": [
    "# Implementing GAU Mean Pooled SBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee148df-2695-4ffc-ac71-5443ec4b43ce",
   "metadata": {},
   "source": [
    "## Implementing GAU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfb1bdd5-693f-4a14-848b-97ada917b5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d64be3c-46d8-4402-9753-0492c4c48a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GatedAttentionUnit(nn.Module):\n",
    "    def __init__(embed_dim=768, intermediate_dim=1536, attn_dim=128):\n",
    "        super(GatedAttentionUnit, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.intermediate_dim = intermediate_dim\n",
    "        self.attn_dim = attn_dim\n",
    "        self.dense_u = nn.Linear(in_features=self.embed_dim,\n",
    "                                 out_features=self.intermediate_dim,\n",
    "                                 bias=False)\n",
    "        self.dense_v = nn.Linear(in_features=self.embed_dim,\n",
    "                                 out_features=self.intermediate_dim,\n",
    "                                 bias=False)\n",
    "        self.attn_dense = nn.Linear(in_features=self.embed_dim,\n",
    "                                    out_features=self.attn_dim,\n",
    "                                    bias=False)\n",
    "        self.gamma_q = nn.Parameter(nn.randn(self.attn_dim))\n",
    "        self.beta_q = nn.Parameter(nn.randn(self.attn_dim))\n",
    "        self.gamma_k= nn.Parameter(nn.randn(self.attn_dim))\n",
    "        self.beta_k= nn.Parameter(nn.randn(self.attn_dim))\n",
    "        \n",
    "        \n",
    "    def attention(self, x, v):\n",
    "        z = self.attn_dense(x)\n",
    "        q = torch.mul(x, self.gamma_q) + self.beta_q\n",
    "        k = torch.mul(x, self.gamma_k) + self.beta_k\n",
    " b      \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d6dd56f-e407-4bb9-8751-1f88537a274c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OffsetScale(nn.Module):\n",
    "    \"\"\"Per dim scaling and offsets\"\"\"\n",
    "    def __init__(self, input_dim, heads=1):\n",
    "        super(OffsetScale, self).__init__()\n",
    "        self.gamma = nn.Parameter(torch.ones(heads, input_dim))\n",
    "        self. beta = nn.Parameter(torch.zeros(heads, input_dim))\n",
    "        # Initialize scale parameter to standard normal values\n",
    "        nn.init.normal_(self.gamma)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = torch.einsum('... d, h d -> ... h d', x, self.gamma) + self.beta\n",
    "        # Split into two values along number of heads\n",
    "        return out.unbind(dim=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a1c9bc0-74e5-407a-861a-5a579d2990e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GatedAttentionUnit(nn.Module):\n",
    "    \"\"\"Gated Attention Unit Implementation from\n",
    "    'Transformer Quality in Linear Time'.\n",
    "    Code mostly adapted from\n",
    "    https://github.com/lucidrains/FLASH-pytorch/blob/main/flash_pytorch/flash_pytorch.py\n",
    "    with added comments for my understanding.\n",
    "    \n",
    "    REMARKS\n",
    "    -------\n",
    "    Relative position bias and masking has not been considered.\n",
    "    This is based on our use-case. The implementation in the provided\n",
    "    lin does have a more generalized setup.\n",
    "    Names of certain variables have been altered for compliance with\n",
    "    the naming convention in the original paper.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        embed_dim=768,\n",
    "        attn_dim=128,\n",
    "        expansion_factor=2,\n",
    "        add_residual=True,\n",
    "        norm=nn.LayerNorm,\n",
    "        activation=nn.SiLU,\n",
    "    ):\n",
    "        super(GatedAttentionUnit, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.hidden_dim = int(self.embed_dim * expansion_factor)\n",
    "        self.attn_dim = attn_dim\n",
    "        self.activation = activation\n",
    "        \n",
    "        self.norm = norm\n",
    "        \n",
    "        # The representations of U and V are both obtained through linear\n",
    "        # transformations followed by an activation.\n",
    "        # As a result, the values of U and V can be obtained\n",
    "        # through a single multiplication and then split into two segments\n",
    "        # by chunking.\n",
    "        # To achieve this, a single weight matrix of twice the\n",
    "        # hidden dimensionality can be used\n",
    "        self.joined_UV = nn.Sequential(\n",
    "            nn.Linear(in_features=self.embed_dim,\n",
    "                      out_features=self.hidden_dim * 2,\n",
    "                      bias=True),\n",
    "            self.activation())\n",
    "        \n",
    "        # Calculate the Z matrix to be used for getting the attention\n",
    "        # matrix A\n",
    "        self.calc_z = nn.Sequential(\n",
    "            nn.Linear(in_features=self.embed_dim,\n",
    "                      out_features=self.attn_dim,\n",
    "                      bias=True),\n",
    "            self.activation())\n",
    "        \n",
    "        # Matrix A is generated with per-dim scaling and offsets\n",
    "        # applied to Z to generate Q and K.\n",
    "        # Instead of doing the operation twice, it can be performed\n",
    "        # once but with an extra dimension which can then be split\n",
    "        # to give Q and K.\n",
    "        self.offset_scale = OffsetScale(input_dim=self.attn_dim,\n",
    "                                        heads=2)\n",
    "        \n",
    "        self.to_output = nn.Linear(in_features=self.hidden_dim,\n",
    "                                   out_features=self.embed_dim,\n",
    "                                   bias=True)\n",
    "        \n",
    "        self.add_residual = add_residual\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        seq_len = x.shape[-2] # Shape is (batch_size, N, embed_dim)\n",
    "        \n",
    "        # Normalization\n",
    "        normed_x = self.norm(x)\n",
    "        \n",
    "        # Get U and V by splitting into two chunks along\n",
    "        # last dimension\n",
    "        # U, V -> (batch_size, N, hidden_dim)\n",
    "        u, v = self.joined_UV(x).chunk(2, dim=-1)\n",
    "        \n",
    "        # Get Z for A calculation\n",
    "        # Z -> (batch_size, N, attn_size)\n",
    "        z = self.calc_z(normed_x)\n",
    "        \n",
    "        # Get Q and K for A calculation\n",
    "        # Q, K -> (batch_size, N, attn_size)\n",
    "        q, k = self.offset_scale(z)\n",
    "        \n",
    "        # Get QK\n",
    "        # QK -> (batch_size, N, N)\n",
    "        qk = torch.einsum('b i d, b j d -> b i j', q, k) * 1./seq_len\n",
    "        \n",
    "        # Omit relative position bias and get A\n",
    "        # A -> (batch_size, N, N)\n",
    "        a = F.relu(qk) ** 2\n",
    "        \n",
    "        # O -> (batch_size, N, hidden_dim)\n",
    "        out = torch.einsum('b i j, b j d -> b i d', a, v)\n",
    "        out = u * out\n",
    "        \n",
    "        # O -> (batch_size, N, embed_dim)\n",
    "        out = self.to_output(out)\n",
    "        \n",
    "        if self.add_residual:\n",
    "            out = out + x\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "017491fe-b2d1-427a-ad59-14ef399dc25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, 512, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca2a4ea0-521c-434d-86a3-a17ac509984d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gau = GatedAttentionUnit(\n",
    "    embed_dim=10,\n",
    "    attn_dim=128,\n",
    "    expansion_factor=2,\n",
    "    add_residual=True,\n",
    "    norm=nn.LayerNorm(10),\n",
    "    activation=nn.SiLU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1213f218-de6a-42f0-b840-ca1e5a93c3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = gau(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c6da75c-2623-40d0-af6b-a6e1b448cd41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 10])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8957e8a8-dd41-4d26-ba4e-2fe7c8253a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GatedAttentionUnit(\n",
       "  (norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "  (joined_UV): Sequential(\n",
       "    (0): Linear(in_features=10, out_features=40, bias=True)\n",
       "    (1): SiLU()\n",
       "  )\n",
       "  (calc_z): Sequential(\n",
       "    (0): Linear(in_features=10, out_features=128, bias=True)\n",
       "    (1): SiLU()\n",
       "  )\n",
       "  (offset_scale): OffsetScale()\n",
       "  (to_output): Linear(in_features=20, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "872c0894-edaa-41e5-9f71-57df52e1e358",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledSinEmbedding(nn.Module):\n",
    "    \"\"\"Scaled Sinusoidal Embeddings\"\"\"\n",
    "    \n",
    "    def __init__(self, dim=768):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.scale = nn.Parameter(torch.ones((1,)))\n",
    "        self.half_d = self.dim // 2\n",
    "        self.inv_freq = 1./ (10000 ** torch.arange(self.half_d).float() / float(self.half_d))\n",
    "        torch.register_buffer('inv_freq', self.inv_freq)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        n = x.shape[1]\n",
    "        t = torch.arange(n).type_as(self.inv_freq)\n",
    "        sinu = torch.einsum('s,d -> sd', t, self.inv_freq)\n",
    "        scaledsin = torch.concat([sinu.sin(), sinu.cos()],axis = -1)\n",
    "        return scaledsin * self.scale\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4f7f866-7bc1-4fb4-9988-7edb57107f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "sinu = ScaledSinEmbedding(dim=768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "548f14eb-563b-47f8-8904-2c63e6f83028",
   "metadata": {},
   "outputs": [],
   "source": [
    "sin_embeds = sinu(torch.randn((1, 72, 768)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25c1fb50-7c0b-4620-bba5-33047f693ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([72, 768])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sin_embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "476bc9ac-9b65-4eba-9c4a-1a94b3cd98b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors = torch.randn((10, 60, 40, 768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "039711bf-9cbc-4544-bd6d-8e0658a2ecb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = list(zip(*map(lambda t: list(t.shape), tensors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13a3a4f3-b339-4e0c-b52d-2f4321122b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(60, 60, 60, 60, 60, 60, 60, 60, 60, 60),\n",
       " (40, 40, 40, 40, 40, 40, 40, 40, 40, 40),\n",
       " (768, 768, 768, 768, 768, 768, 768, 768, 768, 768)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b0832f0-eac5-4219-8f8a-e0460a7cda87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([60, 40, 768],),\n",
       " ([60, 40, 768],),\n",
       " ([60, 40, 768],),\n",
       " ([60, 40, 768],),\n",
       " ([60, 40, 768],),\n",
       " ([60, 40, 768],),\n",
       " ([60, 40, 768],),\n",
       " ([60, 40, 768],),\n",
       " ([60, 40, 768],),\n",
       " ([60, 40, 768],)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(list(map(lambda t: list(t.shape), tensors))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c17304d8-240e-42ef-819c-c04e8b983180",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = -1\n",
    "num_tensors = len(tensors)\n",
    "shape_lens = set(list(map(lambda t: len(t.shape), tensors)))\n",
    "assert len(shape_lens) == 1, 'tensors must all have the same number of dimensions'\n",
    "shape_len = list(shape_lens)[0]\n",
    "\n",
    "dim = (dim + shape_len) if dim < 0 else dim\n",
    "dims = list(zip(*map(lambda t: list(t.shape), tensors)))\n",
    "\n",
    "expandable_dims = [(i, val) for i, val in enumerate(dims) if i != dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cefb850d-1a9a-441d-860a-6117638c84c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d67ff3fd-6ccc-45f8-9481-c91bfd069972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3358e0db-56c0-4286-9237-acf8a76cc554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac430d97-60ec-4a1f-9319-253aa679dffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68e57a17-473c-4d11-a61e-33decb4b544e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, (60, 60, 60, 60, 60, 60, 60, 60, 60, 60)),\n",
       " (1, (40, 40, 40, 40, 40, 40, 40, 40, 40, 40))]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expandable_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3023593-2e41-4707-b048-1fdb2cd17b49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[*map(lambda t: len(set(t[1])) <= 2, expandable_dims)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3379c870-db6e-4ef4-8e6e-b2c5d845b76a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
